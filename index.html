
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta content="Shift happens 2022: Crowdsourcing metrics and test datasets beyond ImageNet " name="title" />
<meta content="This workshop at ICML 2022 aims to enhance and consolidate the landscape of robustness evaluation datasets for computer vision and collect new test sets and metrics for quantifying desirable or problematic properties of computer vision models." lang="en" name="description" xml:lang="en" />

    <title>Shift happens: Crowdsourcing metrics and test datasets beyond ImageNet &#8212; Shift Happens (ICML 2022) 0.0.1-alpha documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Call for Submissions" href="call_for_papers.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="#">
<p class="title">Shift Happens (ICML 2022)</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="call_for_papers.html">
  Call for Submissions
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="call_for_reviewers.html">
  Call for Reviewers
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="api.html">
  Benchmark API Docs
 </a>
</li>

    
    <li class="nav-item">
        <a class="nav-link nav-external" href="https://shift-happens-benchmark.github.io/">Home<i class="fas fa-external-link-alt"></i></a>
    </li>
    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/shift-happens-benchmark/iclr-2022" rel="noopener" target="_blank" title="Github"><span><i class="fab fa-github"></i></span>
            <label class="sr-only">Github</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://pypi.org/project/shifthappens/" rel="noopener" target="_blank" title="PyPI"><span><i class="fab fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://join.slack.com/t/shifthappensicml2022/shared_invite/zt-16ewcukds-6jW6xC5DbtRvLCCkhZ~NLg" rel="noopener" target="_blank" title="Slack"><span><i class="fab fa-slack"></i></span>
            <label class="sr-only">Slack</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="mailto:shifthappens@bethgelab.org" rel="noopener" target="_blank" title="Contact us!"><span><i class="fas fa-envelope"></i></span>
            <label class="sr-only">Contact us!</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#focus-topics">
   Focus Topics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submissions">
   Submissions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#important-deadlines">
   Important Deadlines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prizes-and-travel-grants">
   Prizes and Travel Grants
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#invited-speakers">
   Invited Speakers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#organizers">
   Organizers
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="shift-happens-crowdsourcing-metrics-and-test-datasets-beyond-imagenet">
<h1>Shift happens: Crowdsourcing metrics and test datasets beyond ImageNet<a class="headerlink" href="#shift-happens-crowdsourcing-metrics-and-test-datasets-beyond-imagenet" title="Permalink to this headline">#</a></h1>
<p><em>ICML 2022 workshop</em></p>
<p><strong>We aim to create a community-built benchmark suite for ImageNet models comprised of new datasets for OOD robustness
and detection, as well as new tasks for existing OOD datasets.</strong></p>
<p>While the popularity of robustness benchmarks and new test datasets
increased over the past years, the performance of computer vision models
is still largely evaluated on ImageNet directly, or on simulated or
isolated distribution shifts like in ImageNet-C.</p>
<p><strong>Goal:</strong> This workshop aims to enhance and consolidate the landscape of robustness evaluation datasets for
computer vision and collect new test sets and metrics for quantifying desirable or problematic
properties of computer vision models. Our goal is to bring the robustness, domain
adaptation, and out-of-distribution detection communities together to work on a new
<strong>broad-scale benchmark</strong> that tests diverse aspects of current computer
vision models and guides the way towards the next generation of models.</p>
<table class="table">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><img alt="overview.svg" src="_images/overview.svg" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>Overview over the benchmark suite: You can contribute tasks and
corresponding datasets highlighting
interesting aspects of ImageNet-scale models. We will evaluate
current and future models on the benchmark suite, testing their
robustness, calibration, odd detection, and consistency, and make the
results intuitively accessible in the form of scorecards.</em></p></td>
</tr>
</tbody>
</table>
<p><strong>All accepted submissions will be part of the open-source</strong> <code class="docutils literal notranslate"><span class="pre">shifthappens</span></code> <strong>benchmark suite. This will ensure that after the workshop all benchmarks are accessible to the community.</strong></p>
<p>A central part of our package is to facilitate the evaluation of models on different datasets testing their generalization capabilities and providing fine-grained information on model performance using score-cards. To make sure all contributing authors as well as all authors of used (modified or not) pre-existing datasets will get credit for their efforts, we will release a bibtex file and a ‘cite’ macro for LaTeX which will include all contributions and underlying works.</p>
<p>In addition, participants will have the opportunity to co-author a paper summarizing the benchmark suite and all included contributions.</p>
<section id="focus-topics">
<h2>Focus Topics<a class="headerlink" href="#focus-topics" title="Permalink to this headline">#</a></h2>
<p>Submissions to the benchmark suite will focus on datasets and evaluation algorithms falling into one or more of the categories
below:</p>
<ol class="arabic simple">
<li><p><strong>Robustness to domain shifts:</strong> A labeled
dataset where the labels are (a subset of) the 1000 labels of
ImageNet-2012. Optionally, model calibration, uncertainty, or open
set adaptation can be tested. We especially encourage submissions
focusing on practically relevant distribution shifts.</p></li>
<li><p><strong>Out-of-distribution detection:</strong> A labeled or unlabeled dataset of
images that do not contain objects from any of the 1000 ImageNet-2012
classes.</p></li>
<li><p><strong>New robustness datasets:</strong> Beyond the standard robustness evaluation
settings (with covariate shift, label shift, …), the workshop format
enables submission of datasets that evaluate non-standard metrics
such as the consistency of predictions, influence of spurious
correlations in the dataset.</p></li>
<li><p><strong>New model characteristics:</strong> Metrics and evaluation techniques that
help examine the strengths, weaknesses and peculiarities of models in newly
highlighted respects. Evaluations can utilize established datasets (or
subsets thereof) or come with their own dataset.</p></li>
</ol>
</section>
<section id="submissions">
<h2>Submissions<a class="headerlink" href="#submissions" title="Permalink to this headline">#</a></h2>
<p>The benchmark suite will be available on
<a class="reference external" href="https://github.com/shift-happens-benchmark/icml-2022">GitHub</a>.
The documentation for the benchmark’s API is available <a class="reference external" href="https://shift-happens-benchmark.github.io/icml-2022/">here</a>.
Please see our <a class="reference internal" href="call_for_papers.html"><span class="doc">Call for Submissions</span></a> for more details.</p>
<p>For general questions about preparations of submissions, clarifications around the submission score and
discussions about the <code class="docutils literal notranslate"><span class="pre">shifthappens</span></code> API, please feel free to write us as <a class="reference external" href="mailto:shifthappens&#37;&#52;&#48;bethgelab&#46;org">shifthappens<span>&#64;</span>bethgelab<span>&#46;</span>org</a>
or <a class="reference external" href="https://join.slack.com/t/shifthappensicml2022/shared_invite/zt-16ewcukds-6jW6xC5DbtRvLCCkhZ~NLg">join our slack channel</a>.</p>
</section>
<section id="important-deadlines">
<h2>Important Deadlines<a class="headerlink" href="#important-deadlines" title="Permalink to this headline">#</a></h2>
<p>You can find all deadlines as well as the submission page also directly <a class="reference external" href="https://openreview.net/group?id=ICML.cc/2022/Workshop/Shift_Happens">on OpenReview</a>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://openreview.net/group?id=ICML.cc/2022/Workshop/Shift_Happens">Abstract Deadline</a>: June 3, 2022 (previously: May 27)</p></li>
<li><p><a class="reference external" href="https://openreview.net/group?id=ICML.cc/2022/Workshop/Shift_Happens">Submission Deadline for all extended abstracts and full submissions</a>: June 3, 2022 (previously: May 27)</p></li>
<li><p><a class="reference external" href="https://openreview.net/group?id=ICML.cc/2022/Workshop/Shift_Happens">Special submission Deadline</a>  for all authors of the <a class="reference external" href="https://neurips.cc/Conferences/2022/CallForDatasetsBenchmarks#:~:text=Abstract%20submission%20deadline%3A%20Monday%2C%20June,2022%2001%3A00%20PM%20PDT.">Neurips Datasets &amp; Benchmarks Track submissions</a>: June 9, 2022</p></li>
<li><p>Reviews Posted: June 13, 2022</p></li>
<li><p>Acceptance Notification: June 13, 2022</p></li>
<li><p>Camera and Dataset Ready: July 1, 2022</p></li>
<li><p>ICML 2022 Workshop dates: July 22</p></li>
</ul>
<p>Please note that it is <strong>not required</strong> to post the final dataset by the submission deadline since we are interested in new ideas for feasible datasets.
It is sufficient to start working on final dataset collections after the acceptance notification until the camera ready deadline.</p>
<p>Additional information about submission dates and the submission format can be found in <a class="reference internal" href="call_for_papers.html"><span class="doc">Call for Submissions</span></a>.
Also, please consider our <a class="reference internal" href="call_for_reviewers.html"><span class="doc">Call for Reviewers</span></a>.</p>
</section>
<section id="prizes-and-travel-grants">
<h2>Prizes and Travel Grants<a class="headerlink" href="#prizes-and-travel-grants" title="Permalink to this headline">#</a></h2>
<p>We can offer up to 5 free registrations to the ICML for outstanding submissions.</p>
</section>
<section id="invited-speakers">
<h2>Invited Speakers<a class="headerlink" href="#invited-speakers" title="Permalink to this headline">#</a></h2>
<div class="speakers">
    <div>
        <hr>
        <img style="float: left; margin-right: 20px; max-width: 200px;" alt="Aleksander Madry" src="_static/speakers/aleksander_madry.png">
        <p>
            <a class="reference external" href="https://people.csail.mit.edu/madry/">Aleksander Mądry</a>  is the Cadence Design Systems Professor of Computing at MIT, leads the MIT Center for Deployable Machine Learning as well as is a faculty co-lead for the MIT AI Policy Forum. His research interests span algorithms, continuous optimization, and understanding machine learning from a robustness and deployability perspectives. is the Cadence Design Systems Professor of Computing at MIT, leads the MIT Center for Deployable Machine Learning as well as is a faculty co-lead for the MIT AI Policy Forum. His research interests span algorithms, continuous optimization, and understanding machine learning from a robustness and deployability perspectives.
        </p>
    </div>
    <div>
        <hr>
        <img style="float: left; margin-right: 20px; max-width: 200px;" alt="Alexei Efros" src="_static/speakers/alexei_efros.jpg">
        <p>
            <a class="reference external" href="https://people.eecs.berkeley.edu/~efros/">Alexei Efros</a> is a professor at EECS Department at UC Berkeley, where he is part of the Berkeley Artificial Intelligence Research Lab (BAIR). Before that, he spent nine years on the faculty of the Robotics Institute at CMU. Starting in 2007, Alexei have also been closely collaborating with Team WILLOW at École Normale Supérieure / INRIA in Paris. The central goal of Alexei’s research is to use vast amounts of unlabelled visual data to understand, model, and recreate the visual world around us.
        </p>
    </div>
    <div>
        <hr>
        <img style="float: left; margin-right: 20px; max-width: 200px;" alt="Chelsea Finn" src="_static/speakers/chelsea_finn.jpg">
        <p>
            <a class="reference external" href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> is an Assistant Professor in Computer Science and Electrical Engineering at Stanford University. Her lab, IRIS, studies intelligence through robotic interaction at scale, and is affiliated with SAIL and the ML Group. Chelsea also spends time at Google as a part of the Google Brain team. She is interested in the capability of robots and other agents to develop broadly intelligent behavior through learning and interaction.
        </p>
    </div>
    <div>
        <hr>
        <img style="float: left; margin-right: 20px; max-width: 200px;" alt="Lucas Beyer" src="_static/speakers/lucas_beyer.jpg">
        <p>
            <a class="reference external" href="https://scholar.google.com/citations?user=p2gwhK4AAAAJ&hl=fr">Lucas Beyer</a> grew up in Belgium wanting to make video games and their AI. He went on to study mechanical engineering at RWTH Aachen in Germany, where he did a PhD in robotic perception/computer vision there too, and is now researching representation learning and vision backbones at Google Brain in Zürich.
        </p>
    </div>
    <div>
        <hr>
        <img style="float: left; margin-right: 20px; max-width: 200px;" alt="Ludwig Schmidt" src="_static/speakers/ludwig_schmidt.jpg">
        <p>
            <a class="reference external" href="https://people.csail.mit.edu/ludwigs/">Ludwig Schmidt</a> is an assistant professor in the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Ludwig’s research interests revolve around the empirical and theoretical foundations of machine learning, often with a focus on datasets, evaluation, and reliable methods. Ludwig completed his PhD at MIT under the supervision of Piotr Indyk and was a postdoc at UC Berkeley with Benjamin Recht and Moritz Hardt. Ludwig received a Google PhD fellowship, a Microsoft Simons fellowship, a new horizons award at EAAMO, a best paper award at ICML, and the Sprowls dissertation award from MIT.
        </p>
    </div>
</div>
<hr>
<p>More speakers will be announced soon!</p></section>
<section id="organizers">
<h2>Organizers<a class="headerlink" href="#organizers" title="Permalink to this headline">#</a></h2>
<div class="organizers">
    <div>
        <img alt="Julian Bitterwolf" src="_static/organizers/julian_bitterwolf.png">
        <br>
        <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/maschinelles-lernen/team/julian-bitterwolf-msc/">Julian Bitterwolf</a>
    </div>
    <div>
        <img alt="Evgenia Rusak" src="_static/organizers/evgenia_rusak.png">
        <br>
        <a href="https://scholar.google.com/citations?user=XKc19kkAAAAJ&hl=en&oi=ao">Evgenia Rusak</a>
    </div>
    <div>
        <img alt="Steffen Schneider" src="_static/organizers/steffen_schneider.jpeg">
        <br>
        <a href="https://stes.io/">Steffen Schneider</a>
    </div>
    <div>
        <img alt="Roland S. Zimmermann" src="_static/organizers/roland_zimmermann.png">
        <br>
        <a href="https://rzimmermann.com/">Roland S. Zimmermann</a>
    </div>
    <div>
        <img alt="Matthias Bethge" src="_static/organizers/matthias_bethge.png">
        <br>
        <a href="http://bethgelab.org/">Matthias Bethge</a>
    </div>
    <div>
        <img alt="Wieland Brendel" src="_static/organizers/wieland_brendel.png">
        <br>
        <a href="https://scholar.google.com/citations?user=v-JL-hsAAAAJ&hl=en&oi=ao">Wieland Brendel</a>
    </div>
    <div>
        <img alt="Matthias Hein" src="_static/organizers/matthias_hein.png">
        <br>
        <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/maschinelles-lernen/team/prof-dr-matthias-hein/">Matthias Hein</a>
    </div>
</div><div class="toctree-wrapper compound">
</div>
</section>
</section>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021 - 2022, Julian Bitterwolf, Evgenia Rusak, Steffen Schneider, Roland S. Zimmermann and contributors. Released under an Apache 2.0 License.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>